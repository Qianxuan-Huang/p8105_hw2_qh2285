Homework 2
================
Qianxuan Hunag
2024-10-01

``` r
library(tidyverse)
library(readxl)
library(ggplot2)
```

## Problem 1

Below is code of importing
`NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. Change `Route` columns
8-11 to character as same as 1-7. Then update variable names, and
selects the columns we need. Change `entry` from `yes` / `no` to a
logical variable.

``` r
trans_ent = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations. .

``` r
trans_ent %>% 
  select(station_name, line) %>% 
  distinct()
## # A tibble: 465 × 2
##    station_name             line    
##    <chr>                    <chr>   
##  1 25th St                  4 Avenue
##  2 36th St                  4 Avenue
##  3 45th St                  4 Avenue
##  4 53rd St                  4 Avenue
##  5 59th St                  4 Avenue
##  6 77th St                  4 Avenue
##  7 86th St                  4 Avenue
##  8 95th St                  4 Avenue
##  9 9th St                   4 Avenue
## 10 Atlantic Av-Barclays Ctr 4 Avenue
## # ℹ 455 more rows
```

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct()
## # A tibble: 84 × 2
##    station_name                   line           
##    <chr>                          <chr>          
##  1 Atlantic Av-Barclays Ctr       4 Avenue       
##  2 DeKalb Av                      4 Avenue       
##  3 Pacific St                     4 Avenue       
##  4 Grand Central                  42nd St Shuttle
##  5 34th St                        6 Avenue       
##  6 47-50th Sts Rockefeller Center 6 Avenue       
##  7 Church Av                      6 Avenue       
##  8 21st St                        63rd Street    
##  9 Lexington Av                   63rd Street    
## 10 Roosevelt Island               63rd Street    
## # ℹ 74 more rows
```

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean()
## [1] 0.3770492
```

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct()
## # A tibble: 60 × 2
##    station_name                  line           
##    <chr>                         <chr>          
##  1 Times Square                  42nd St Shuttle
##  2 125th St                      8 Avenue       
##  3 145th St                      8 Avenue       
##  4 14th St                       8 Avenue       
##  5 168th St - Washington Heights 8 Avenue       
##  6 175th St                      8 Avenue       
##  7 181st St                      8 Avenue       
##  8 190th St                      8 Avenue       
##  9 34th St                       8 Avenue       
## 10 42nd St                       8 Avenue       
## # ℹ 50 more rows

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct()
## # A tibble: 17 × 2
##    station_name                  line            
##    <chr>                         <chr>           
##  1 14th St                       8 Avenue        
##  2 168th St - Washington Heights 8 Avenue        
##  3 175th St                      8 Avenue        
##  4 34th St                       8 Avenue        
##  5 42nd St                       8 Avenue        
##  6 59th St                       8 Avenue        
##  7 Inwood - 207th St             8 Avenue        
##  8 West 4th St                   8 Avenue        
##  9 World Trade Center            8 Avenue        
## 10 Times Square-42nd St          Broadway        
## 11 59th St-Columbus Circle       Broadway-7th Ave
## 12 Times Square                  Broadway-7th Ave
## 13 8th Av                        Canarsie        
## 14 Franklin Av                   Franklin        
## 15 Euclid Av                     Fulton          
## 16 Franklin Av                   Fulton          
## 17 Howard Beach                  Rockaway
```

## Problem 2

tidy up Mr. Trash Wheel sheet:

``` r
mr_trash_wheel_df = 
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel", , na = c("NA", "", "."),
             col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls))) 
```

tidy up Professor Trash Wheel sheet:

``` r
pr_trash_wheel_df = 
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel", , na = c("NA", "", "."),
             col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) 
```

tidy up Gwynnda Trash Wheel sheet:

``` r
gw_trash_wheel_df = 
  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",  na = c("NA", "", "."),
             col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) 
```

add an additional variable of sheet name:

``` r
mr_trash_wheel_df = mutate(pr_trash_wheel_df, trash_wheel = "Mr. Trash Wheel")
pr_trash_wheel_df = mutate(pr_trash_wheel_df, trash_wheel = "Professor Trash Wheel")
gw_trash_wheel_df = mutate(pr_trash_wheel_df, trash_wheel = "Gwynnda Trash Wheel")
```

combine 3 tabels together:

``` r
trash_wheel_df <- bind_rows(mr_trash_wheel_df, pr_trash_wheel_df, gw_trash_wheel_df)

trash_wheel_df
## # A tibble: 357 × 14
##    dumpster month     year date                weight_tons volume_cubic_yards
##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
## # ℹ 347 more rows
## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
## #   wrappers <dbl>, homes_powered <dbl>, trash_wheel <chr>
```

### summarizing the dataset

The number of observations in “Mr. Trash Wheel” is 263, in “Professor
Trash Wheel” is 119, in “Gwynnda Trash Wheel” is 263, 789 observations
in total:

``` r
nrow(trash_wheel_df)
## [1] 357
nrow(mr_trash_wheel_df)
## [1] 119
nrow(pr_trash_wheel_df)
## [1] 119
nrow(gw_trash_wheel_df)
## [1] 119
```

key variables: All 3 tables show weight, date, Homes Powered or not, and
different kinds of trash, such as Plastic Bottles, Polystyrene,
Cigarette Butts, Glass Bottles, Plastic Bags, Wrappers. And “Mr. Trash
Wheel” includes extra kind Sports Balls.

total weight of trash collected by Professor Trash Wheel is 246.74 tons:

``` r
total_weight_pr = pr_trash_wheel_df %>% 
  summarize(sum(weight_tons, na.rm = TRUE))

total_weight_pr
## # A tibble: 1 × 1
##   `sum(weight_tons, na.rm = TRUE)`
##                              <dbl>
## 1                             247.
```

total number of cigarette butts collected by Gwynnda in June of 2022 is
18120:

``` r
total_butts = gw_trash_wheel_df %>%
  filter(month == "June" & year == 2022) %>%
  summarize(sum(cigarette_butts, na.rm = TRUE))

total_butts
## # A tibble: 1 × 1
##   `sum(cigarette_butts, na.rm = TRUE)`
##                                  <dbl>
## 1                                11600
```

## problem 3

import, clean, tidy, and otherwise wrangle each of all datasets:

``` r
bakers_df = 
  read_csv("./data/gbb_datasets/bakers.csv",  na = c("NA", "", "."),
             col_names = TRUE) %>% 
  janitor::clean_names() %>%
  mutate(baker_first_name = word(baker_name, 1)) 

bakes_df = 
  read_csv("./data/gbb_datasets/bakes.csv",  na = c("NA", "", "."),
             col_names = TRUE) %>% 
  janitor::clean_names() 

results_df = 
  read_csv("./data/gbb_datasets/results.csv",  na = c("NA", "", "."),
             col_names = TRUE) %>% 
  janitor::clean_names() 

viewers_df =
  read_csv("./data/gbb_datasets/viewers.csv",  na = c("NA", "", "."),
             col_names = TRUE) %>% 
  janitor::clean_names() %>%
  pivot_longer(cols = starts_with("series_"), 
               names_to = "series", 
               names_prefix = "series_", 
               values_to = "viewers") %>%
  mutate(series = as.integer(series))
```

check for completeness and correctness across datasets (e.g. by viewing
individual datasets and using anti_join):

``` r
anti_join(bakes_df, bakers_df, by = c("baker" = "baker_first_name"))
## # A tibble: 8 × 5
##   series episode baker    signature_bake                            show_stopper
##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…
```

change all values include “Jo”

``` r
bakes_df = mutate(bakes_df,
                  baker = ifelse(baker == "\"Jo\"", "Jo", baker))
```

merge to create a single, final dataset, and organize this so that
variables and observations are in meaningful orders:

``` r
gbb_df = 
  left_join(bakers_df, bakes_df, by = c("baker_first_name" = "baker", 
                                        "series" = "series")) 
```

Export the result as a CSV in the directory containing the original
datasets:

``` r
write.csv(gbb_df, file = file.path("./data/gbb_datasets", "gbb_df.csv"), row.names = FALSE)
```

discuss the final dataset:

Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10:

Import, clean, tidy, and organize the viewership data in viewers.csv.
Show the first 10 rows of this dataset:

``` r
viewers_df %>% arrange("series", "episode") %>%  
  head(10) %>%
  print()
## # A tibble: 10 × 3
##    episode series viewers
##      <dbl>  <int>   <dbl>
##  1       1      1    2.24
##  2       1      2    3.1 
##  3       1      3    3.85
##  4       1      4    6.6 
##  5       1      5    8.51
##  6       1      6   11.6 
##  7       1      7   13.6 
##  8       1      8    9.46
##  9       1      9    9.55
## 10       1     10    9.62
```

average viewership in Season 1 is 2.77000. In Season 5 is 10.03930:

``` r
avg_viewership_by_season = 
  viewers_df %>%
  group_by(series) %>%
  summarise(
    average_viewers = mean(viewers, na.rm = TRUE)
  )

avg_viewership_by_season
## # A tibble: 10 × 2
##    series average_viewers
##     <int>           <dbl>
##  1      1            2.77
##  2      2            3.95
##  3      3            5.00
##  4      4            7.35
##  5      5           10.0 
##  6      6           12.3 
##  7      7           13.6 
##  8      8            9.02
##  9      9            9.30
## 10     10            9.24
```
